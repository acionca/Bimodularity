{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import datasets, image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpecFromSubplotSpec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from seaborn import kdeplot\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import importlib\n",
    "\n",
    "import dgsp\n",
    "import bimod_plots as plot\n",
    "import clustering as e_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aabf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CopyPasted from utils.py in other repo:\n",
    "import pickle\n",
    "\n",
    "path_to_save = \"./data/brain-benchmark\"\n",
    "os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "def save(pickle_filename: str, iterable: object) -> None:\n",
    "    \"\"\"\n",
    "    Pickle an object to a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pickle_filename : str\n",
    "        Path to the file where the object will be pickled.\n",
    "    iterable : object\n",
    "        The object to be pickled.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(pickle_filename, \"wb\") as handle:\n",
    "        pickle.dump(iterable, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load(pickle_filename: str) -> object:\n",
    "    \"\"\"\n",
    "    Load a pickled object from the specified file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pickle_filename : str\n",
    "        The filename of the pickled object to load.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    object\n",
    "        The loaded object.\n",
    "    \"\"\"\n",
    "    with open(pickle_filename, \"rb\") as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ce1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./data/brain\"\n",
    "\n",
    "# Could be 50, 100, 200, 400\n",
    "delay_max = 100\n",
    "#delay_max = 100\n",
    "scale = 1\n",
    "\n",
    "undirected = True\n",
    "\n",
    "filename = f\"bundle_probability_atlas-scale{scale}.pkl\"\n",
    "\n",
    "bundle_prob = load(op.join(path_to_data, filename))\n",
    "bundle_prob = bundle_prob[:-2][:, :-2]\n",
    "bundle_prob -= np.diag(np.diag(bundle_prob))\n",
    "ftract_prob = load(op.join(path_to_data, f\"adj_probability_ftract-d{delay_max}-scale{scale}.pkl\"))\n",
    "ftract_prob = ftract_prob[:-2][:, :-2]\n",
    "\n",
    "print(bundle_prob.shape)\n",
    "print(ftract_prob.shape)\n",
    "\n",
    "node_centers = load(op.join(path_to_data, f\"roi_centers-ftract-scale{scale}.pkl\"))[:82]\n",
    "height_scale = node_centers[:, 2] - node_centers[:, 2].min()\n",
    "height_scale = height_scale / height_scale.max()\n",
    "\n",
    "scale_to_nroi = {1:\"33\", 2:\"60\", 3:\"125\"}\n",
    "\n",
    "labels = np.genfromtxt(op.join(path_to_data, f\"brain_labels.csv\"), dtype=str)\n",
    "\n",
    "print(f\"There are {len(labels)} nodes in the graph\")\n",
    "all_types = [\"lh\", \"rh\", \"lhsc\", \"rhsc\"]\n",
    "types_rename = [\"Left\", \"Right\", \"Left-sub\", \"Right-sub\"]\n",
    "type2num = {t:i for i, t in enumerate(all_types)}\n",
    "\n",
    "node_type = [type2num[lab.split(\"-\")[0]] for lab in labels]\n",
    "\n",
    "k_threshold = 0.9\n",
    "\n",
    "if undirected:\n",
    "    k_matrix = (bundle_prob.copy() > k_threshold).astype(int)\n",
    "    # k_matrix = bundle_prob + bundle_prob.T\n",
    "else:\n",
    "    k_matrix = (2 * bundle_prob * ftract_prob)/(ftract_prob + ftract_prob.T)\n",
    "    k_matrix = (k_matrix >= k_threshold).astype(int)\n",
    "\n",
    "print(\"Is it undirected ?\", np.allclose(k_matrix, k_matrix.T))\n",
    "graph = k_matrix.copy()\n",
    "n_nodes = graph.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_all_fmri = \"/Users/acionca/data/HCP-MIP/atlased/Laus2008_smth6_lp0.15\"\n",
    "\n",
    "task = \"rest1_dir-LR\"\n",
    "# task = \"rest1\"\n",
    "# task = \"motor\"\n",
    "# task = \"emotion\"\n",
    "# task = \"gambling\"\n",
    "# task = \"language\"\n",
    "\n",
    "all_fnames = sorted([f for f in os.listdir(path_to_all_fmri) if task in f])\n",
    "print(all_fnames)\n",
    "print(f\"Found {len(all_fnames)} matching files\")\n",
    "\n",
    "all_nodals = [np.genfromtxt(op.join(path_to_all_fmri, f), delimiter=\",\") for f in all_fnames]\n",
    "\n",
    "nodal_fmri = np.concatenate(all_nodals, axis=0)\n",
    "print(nodal_fmri.shape)\n",
    "\n",
    "test = np.concatenate(all_nodals[:len(all_nodals)//2], axis=0)\n",
    "retest = np.concatenate(all_nodals[len(all_nodals)//2:], axis=0)\n",
    "\n",
    "del all_nodals\n",
    "\n",
    "ntest = len(test)\n",
    "nretest = len(retest)\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(f\"Retest shape: {retest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5aa58d",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b12786",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "operators = [\"naive\", \"modularity\", \"laplacian\", \"adjacency\"]\n",
    "operators = [\"modularity\", \"laplacian\"]\n",
    "\n",
    "norm_cluster = True\n",
    "sqrt = True\n",
    "\n",
    "all_comps = np.arange(2, 10)\n",
    "all_k_clusters = np.arange(2, 20)\n",
    "\n",
    "# all_comps = np.arange(2, 20)\n",
    "# all_k_clusters = np.arange(2, 20)\n",
    "\n",
    "auto_figsize = ((len(all_k_clusters)+2)//2, (len(all_comps)+2)//2)\n",
    "\n",
    "stat_test = np.concatenate([test.T, test.T], axis=0).T\n",
    "stat_retest = np.concatenate([retest.T, retest.T], axis=0).T\n",
    "\n",
    "stat_test_edge, stat_retest_edge = e_clust.prepare_benchmark(graph, stat_test, stat_retest, all_comps, operators, sqrt=sqrt)\n",
    "\n",
    "stat_test_edge = stat_test_edge/np.linalg.norm(stat_test_edge, axis=3)[..., None]\n",
    "stat_retest_edge = stat_retest_edge/np.linalg.norm(stat_retest_edge, axis=3)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006628d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "fname = f\"static{'-sqrt'*sqrt}-{task}{len(all_fnames)}-n{len(all_comps)}-k{len(all_k_clusters)}-scale{scale}.pkl\"\n",
    "if overwrite or not op.isfile(op.join(path_to_save, fname)):\n",
    "    (test_labels,\n",
    "    retest_labels,\n",
    "    test_centroids,\n",
    "    retest_centroids) = e_clust.benchmark_clustering_fast(\n",
    "        stat_test_edge,\n",
    "        stat_retest_edge,\n",
    "        all_k_clusters=all_k_clusters,\n",
    "        norm=False)\n",
    "\n",
    "    save(op.join(path_to_save, fname),\n",
    "        {\"test_labels\": test_labels,\n",
    "        \"retest_labels\": retest_labels,\n",
    "        \"test_centroids\": test_centroids,\n",
    "        \"retest_centroids\": retest_centroids})\n",
    "else:\n",
    "    data = load(op.join(path_to_save, fname))\n",
    "    test_labels = data[\"test_labels\"]\n",
    "    retest_labels = data[\"retest_labels\"]\n",
    "    test_centroids = data[\"test_centroids\"]\n",
    "    retest_centroids = data[\"retest_centroids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "operators = [\"naive\", \"modularity\", \"laplacian\", \"adjacency\"]\n",
    "operators = [\"modularity\", \"laplacian\"]\n",
    "\n",
    "norm_cluster = True\n",
    "\n",
    "stat_test = np.concatenate([test.T, test.T], axis=0).T\n",
    "stat_retest = np.concatenate([retest.T, retest.T], axis=0).T\n",
    "\n",
    "# test_labels, retest_labels, test_centroids, retest_centroids = e_clust.benchmark_clustering(graph, stat_test, stat_retest,\n",
    "#                                                                                             all_comps=all_comps,\n",
    "#                                                                                             all_k_clusters=all_k_clusters,\n",
    "#                                                                                             all_operators=operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5964f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels.shape)\n",
    "print(retest_labels.shape)\n",
    "\n",
    "print(len(test_centroids))\n",
    "print(len(retest_centroids))\n",
    "\n",
    "print(test_centroids[0].shape)\n",
    "print(retest_centroids[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(all_comps), ncols=len(all_k_clusters), figsize=(len(all_k_clusters), len(all_comps)), gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1})\n",
    "\n",
    "fig.suptitle(f\"Matched Centroid Correlation ({operators[0].capitalize()})\", fontsize=16)\n",
    "\n",
    "axes[len(all_comps)//2, 0].set_ylabel(f\"$n$\", fontsize=16)\n",
    "axes[0, len(all_k_clusters)//2].set_title(f\"$k$\", fontsize=16)\n",
    "\n",
    "all_cent_corr = [np.zeros((len(all_comps), len(operators), k, k)) for k in all_k_clusters]\n",
    "all_cent_match = [np.zeros((len(all_comps), len(operators), k, k)) for k in all_k_clusters]\n",
    "all_diag_means = np.zeros((len(all_k_clusters), len(all_comps), len(operators)), dtype=float)\n",
    "all_off_diag_means = np.zeros((len(all_k_clusters), len(all_comps), len(operators)), dtype=float)\n",
    "\n",
    "for k, k_clust in enumerate(all_k_clusters):\n",
    "    for n, n_comp in enumerate(all_comps):\n",
    "        for i, operator in enumerate(operators):\n",
    "            corr_input = np.vstack([test_centroids[k][n, i], retest_centroids[k][n, i]])\n",
    "            all_cent_corr[k][n, i] = np.corrcoef(corr_input)[:k_clust][:, k_clust:]\n",
    "\n",
    "            row_ind, col_ind = linear_sum_assignment(all_cent_corr[k][n, i], maximize=True)\n",
    "            all_cent_match[k][n, i] = all_cent_corr[k][n, i][row_ind][:, col_ind]\n",
    "\n",
    "            all_diag_means[k, n, i] = np.diag(all_cent_match[k][n, i]).mean()\n",
    "            # all_off_diag_means[k, n, i] = all_cent_match[k][n, i][~np.eye(k_clust, dtype=bool)].mean()\n",
    "            all_off_diag_means[k, n, i] = np.abs(all_cent_match[k][n, i][~np.eye(k_clust, dtype=bool)]).mean()\n",
    "        \n",
    "        axes[n, k].imshow(all_cent_match[k][n, 0], vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "        axes[n, k].set_xticks([])\n",
    "        axes[n, k].set_yticks([])\n",
    "\n",
    "        axes[n, 0].set_yticks([0.5], [f\"{n_comp}\"], fontsize=16)\n",
    "    axes[0, k].set_xticks([(k_clust-1)/2], [f\"{k_clust}\"], fontsize=16)\n",
    "    axes[0, k].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(all_comps), ncols=len(all_k_clusters), figsize=(len(all_k_clusters), len(all_comps)), gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1})\n",
    "\n",
    "fig.suptitle(f\"Matched Centroid Correlation ({operators[1].capitalize()})\", fontsize=16)\n",
    "\n",
    "axes[len(all_comps)//2, 0].set_ylabel(f\"$n$\", fontsize=16)\n",
    "axes[0, len(all_k_clusters)//2].set_title(f\"$k$\", fontsize=16)\n",
    "\n",
    "for k, k_clust in enumerate(all_k_clusters):\n",
    "    for n, n_comp in enumerate(all_comps):\n",
    "        axes[n, k].imshow(all_cent_match[k][n, 1], vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "        axes[n, k].set_xticks([])\n",
    "        axes[n, k].set_yticks([])\n",
    "\n",
    "        axes[n, 0].set_yticks([0.5], [f\"{n_comp}\"], fontsize=16)\n",
    "    axes[0, k].set_xticks([(k_clust-1)/2], [f\"{k_clust}\"], fontsize=16)\n",
    "    axes[0, k].tick_params(top=True, labeltop=True, bottom=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=auto_figsize, gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1})\n",
    "\n",
    "fig.suptitle(f\"Static Signals $([x_t$  $x_t]^T)$\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.set_title(operators[i].capitalize(), fontsize=16)\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(all_diag_means[:, :, i].T, vmin=all_diag_means.min(), vmax=1, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "axes[1, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "\n",
    "all_ratios = np.abs(all_diag_means / all_off_diag_means)\n",
    "print(all_ratios.min(), all_ratios.max())\n",
    "minval = 2\n",
    "maxval = 5\n",
    "\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(all_ratios[:, :, i].T, vmin=minval, vmax=maxval, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    ax.set_xlabel(\"$k$\", fontsize=16)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04c0b3",
   "metadata": {},
   "source": [
    "## Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5c4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "trans_test = np.concatenate([test.T[:, :-1], test.T[:, 1:]], axis=0).T\n",
    "trans_retest = np.concatenate([retest.T[:, :-1], retest.T[:, 1:]], axis=0).T\n",
    "\n",
    "# trans_test_edge, trans_retest_edge = e_clust.prepare_benchmark(graph, trans_test, trans_retest, all_comps, operators)\n",
    "# trans_test_edge = trans_test_edge/np.linalg.norm(trans_test_edge, axis=3)[..., None]\n",
    "# trans_retest_edge = trans_retest_edge/np.linalg.norm(trans_retest_edge, axis=3)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f\"trans-{task}{len(all_fnames)}-n{len(all_comps)}-k{len(all_k_clusters)}-scale{scale}.pkl\"\n",
    "if overwrite or (not op.isfile(op.join(path_to_save, fname))):\n",
    "    # (trans_t_lab, trans_rt_lab, trans_t_cent, trans_rt_cent) = (\n",
    "    #     e_clust.benchmark_clustering(\n",
    "    #         graph,\n",
    "    #         trans_test,\n",
    "    #         trans_retest,\n",
    "    #         all_comps=all_comps,\n",
    "    #         all_k_clusters=all_k_clusters,\n",
    "    #         all_operators=operators,\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    (trans_t_lab,\n",
    "     trans_rt_lab,\n",
    "     trans_t_cent,\n",
    "     trans_rt_cent) = e_clust.benchmark_clustering_fast(\n",
    "         trans_test_edge,\n",
    "         trans_retest_edge,\n",
    "         all_k_clusters=all_k_clusters,\n",
    "         norm=False)\n",
    "\n",
    "    save(op.join(path_to_save, fname),\n",
    "        {\"test_labels\": trans_t_lab,\n",
    "        \"retest_labels\": trans_rt_lab,\n",
    "        \"test_centroids\": trans_t_cent,\n",
    "        \"retest_centroids\": trans_rt_cent})\n",
    "else:\n",
    "    data = load(op.join(path_to_save, fname))\n",
    "    trans_t_lab = data[\"test_labels\"]\n",
    "    trans_rt_lab = data[\"retest_labels\"]\n",
    "    trans_t_cent = data[\"test_centroids\"]\n",
    "    trans_rt_cent = data[\"retest_centroids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "trans_cent_match, trans_diag_means, trans_off_diag_means = e_clust.get_centroid_similarities(trans_t_cent, trans_rt_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=auto_figsize, gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1})\n",
    "\n",
    "fig.suptitle(f\"Transition Signals $([x_t$  $x_{{t+1}}]^T)$\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.set_title(operators[i].capitalize(), fontsize=16)\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    # ax.imshow(trans_diag_means[:, :, i].T, vmin=trans_diag_means.min(), vmax=1, cmap=\"Reds\")\n",
    "    ax.imshow(trans_diag_means[:, :, i].T, vmin=all_diag_means.min(), vmax=1, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "axes[1, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "\n",
    "all_ratios = np.abs(trans_diag_means / trans_off_diag_means)\n",
    "print(all_ratios.min(), all_ratios.max())\n",
    "minval = 2\n",
    "maxval = 5\n",
    "\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(all_ratios[:, :, i].T, vmin=minval, vmax=maxval, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    ax.set_xlabel(\"$k$\", fontsize=16)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db3fce",
   "metadata": {},
   "source": [
    "## Static without DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86236dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "fname = f\"static_NoDC-{task}{len(all_fnames)}-n{len(all_comps)}-k{len(all_k_clusters)}-scale{scale}.pkl\"\n",
    "if overwrite or not op.isfile(op.join(path_to_save, fname)):\n",
    "    (test_labels_noDC,\n",
    "    retest_labels_noDC,\n",
    "    test_centroids_noDC,\n",
    "    retest_centroids_noDC) = e_clust.benchmark_clustering(\n",
    "        graph, stat_test, stat_retest,\n",
    "        all_comps=all_comps,\n",
    "        all_k_clusters=all_k_clusters,\n",
    "        all_operators=operators,\n",
    "        start_comp=[0, 1])\n",
    "\n",
    "    save(op.join(path_to_save, fname),\n",
    "        {\"test_labels\": test_labels_noDC,\n",
    "        \"retest_labels\": retest_labels_noDC,\n",
    "        \"test_centroids\": test_centroids_noDC,\n",
    "        \"retest_centroids\": retest_centroids_noDC})\n",
    "else:\n",
    "    data = load(op.join(path_to_save, fname))\n",
    "    test_labels_noDC = data[\"test_labels\"]\n",
    "    retest_labels_noDC = data[\"retest_labels\"]\n",
    "    test_centroids_noDC = data[\"test_centroids\"]\n",
    "    retest_centroids_noDC = data[\"retest_centroids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(stat_cent_match_noDC,\n",
    " stat_diag_means_noDC,\n",
    " stat_off_diag_means_noDC,) = e_clust.get_centroid_similarities(test_centroids_noDC, retest_centroids_noDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234efe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=auto_figsize, gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1})\n",
    "\n",
    "fig.suptitle(f\"Static Signals $([x_t$  $x_t]^T)$ - No DC for Laplacian\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.set_title(operators[i].capitalize(), fontsize=16)\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(stat_diag_means_noDC[:, :, i].T, vmin=stat_diag_means_noDC.min(), vmax=1, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "axes[1, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "\n",
    "all_ratios = np.abs(stat_diag_means_noDC / stat_off_diag_means_noDC)\n",
    "print(all_ratios.min(), all_ratios.max())\n",
    "minval = 2\n",
    "maxval = 5\n",
    "\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(all_ratios[:, :, i].T, vmin=minval, vmax=maxval, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    ax.set_xlabel(\"$k$\", fontsize=16)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(e_clust)\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "fname = f\"trans_NoDC-{task}{len(all_fnames)}-n{len(all_comps)}-k{len(all_k_clusters)}-scale{scale}.pkl\"\n",
    "if overwrite or not op.isfile(op.join(path_to_save, fname)):\n",
    "    (trans_t_lab_noDC,\n",
    "    trans_rt_lab_noDC,\n",
    "    trans_t_cent_noDC,\n",
    "    trans_rt_cent_noDC) = e_clust.benchmark_clustering(graph, trans_test, trans_retest,\n",
    "                                                        all_comps=all_comps,\n",
    "                                                        all_k_clusters=all_k_clusters,\n",
    "                                                        all_operators=operators,\n",
    "                                                        start_comp=[0, 1])\n",
    "\n",
    "    save(op.join(path_to_save, fname),\n",
    "        {\"test_labels\": trans_t_lab_noDC,\n",
    "        \"retest_labels\": trans_rt_lab_noDC,\n",
    "        \"test_centroids\": trans_t_cent_noDC,\n",
    "        \"retest_centroids\": trans_rt_cent_noDC})\n",
    "else:\n",
    "    data = load(op.join(path_to_save, fname))\n",
    "    trans_t_lab_noDC = data[\"test_labels\"]\n",
    "    trans_rt_lab_noDC = data[\"retest_labels\"]\n",
    "    trans_t_cent_noDC = data[\"test_centroids\"]\n",
    "    trans_rt_cent_noDC = data[\"retest_centroids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trans_cent_match_noDC,\n",
    " trans_diag_means_noDC,\n",
    " trans_off_diag_means_noDC,) = e_clust.get_centroid_similarities(trans_t_cent_noDC, trans_rt_cent_noDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd072841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=auto_figsize, gridspec_kw={\"hspace\": 0.1, \"wspace\": 0.1})\n",
    "\n",
    "fig.suptitle(f\"Transition Signals $([x_t$  $x_{{t+1}}]^T)$ - No DC for Laplacian\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.set_title(operators[i].capitalize(), fontsize=16)\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(trans_diag_means_noDC[:, :, i].T, vmin=trans_diag_means_noDC.min(), vmax=1, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "axes[1, 0].set_ylabel(\"$n$\", fontsize=16)\n",
    "\n",
    "all_ratios = np.abs(trans_diag_means_noDC / trans_off_diag_means_noDC)\n",
    "print(all_ratios.min(), all_ratios.max())\n",
    "minval = 2\n",
    "maxval = 5\n",
    "\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    # ax.imshow(all_diag_means[:, :, i].T, vmin=-1, vmax=1, cmap=\"coolwarm\")\n",
    "    ax.imshow(all_ratios[:, :, i].T, vmin=minval, vmax=maxval, cmap=\"Reds\")\n",
    "    ax.set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "    ax.set_yticks(np.arange(len(all_comps)), labels=all_comps)\n",
    "    ax.set_xlabel(\"$k$\", fontsize=16)\n",
    "    if i == 0:\n",
    "        _ = plot.add_cbar(fig, ax, ticks=[])\n",
    "    else:\n",
    "        _ = plot.add_cbar(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bcd06",
   "metadata": {},
   "source": [
    "## Plotting Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60fec53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355d853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a32c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc30b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 5), gridspec_kw={\"hspace\": 0, \"wspace\": 0}, sharex=True, sharey=\"row\")\n",
    "\n",
    "fig.suptitle(f\"Transition Signals $([x_t$  $x_{{t+1}}]^T)$ - No DC for Laplacian\", fontsize=16)\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\", len(all_comps)+2)\n",
    "\n",
    "axes[0, 0].set_xticks(np.arange(len(all_k_clusters)), labels=all_k_clusters)\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    ax.set_title(operators[i].capitalize(), fontsize=16)\n",
    "    for k, diag in enumerate(trans_diag_means_noDC[:, :, i].T):\n",
    "        ax.plot(diag, color=cmap(k+1), label=all_comps[k], lw=2)\n",
    "    # ax.legend(title=\"n\", ncols=len(all_comps), loc=\"lower right\", fontsize=10)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Diag\", fontsize=16)\n",
    "axes[1, 0].set_ylabel(\"Diag/Off-Diag\", fontsize=16)\n",
    "\n",
    "all_ratios = np.abs(trans_diag_means_noDC / trans_off_diag_means_noDC)\n",
    "print(all_ratios.min(), all_ratios.max())\n",
    "minval = 1.1\n",
    "maxval = 3.4\n",
    "\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    for k, ratio in enumerate(all_ratios[:, :, i].T):\n",
    "        ax.plot(ratio, color=cmap(k+1), label=all_comps[k], lw=2)\n",
    "    ax.set_xlabel(\"$k$\", fontsize=16)\n",
    "    ax.set_ylim(minval, maxval)\n",
    "    \n",
    "    # ax.legend(title=\"n\", ncols=len(all_comps), loc=\"lower right\", fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df11422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
