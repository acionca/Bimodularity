{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import datasets, image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpecFromSubplotSpec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from seaborn import kdeplot\n",
    "\n",
    "import importlib\n",
    "\n",
    "import dgsp\n",
    "import bimod_plots as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Brain Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CopyPasted from utils.py in other repo:\n",
    "import pickle\n",
    "\n",
    "def save(pickle_filename: str, iterable: object) -> None:\n",
    "    \"\"\"\n",
    "    Pickle an object to a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pickle_filename : str\n",
    "        Path to the file where the object will be pickled.\n",
    "    iterable : object\n",
    "        The object to be pickled.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(pickle_filename, \"wb\") as handle:\n",
    "        pickle.dump(iterable, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load(pickle_filename: str) -> object:\n",
    "    \"\"\"\n",
    "    Load a pickled object from the specified file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pickle_filename : str\n",
    "        The filename of the pickled object to load.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    object\n",
    "        The loaded object.\n",
    "    \"\"\"\n",
    "    with open(pickle_filename, \"rb\") as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./data/brain\"\n",
    "\n",
    "# Could be 50, 100, 200, 400\n",
    "delay_max = 100\n",
    "#delay_max = 100\n",
    "scale = 1\n",
    "\n",
    "filename = f\"bundle_probability_atlas-scale{scale}.pkl\"\n",
    "\n",
    "bundle_prob = load(op.join(path_to_data, filename))\n",
    "bundle_prob = bundle_prob[:-2][:, :-2]\n",
    "bundle_prob -= np.diag(np.diag(bundle_prob))\n",
    "ftract_prob = load(op.join(path_to_data, f\"adj_probability_ftract-d{delay_max}-scale{scale}.pkl\"))\n",
    "ftract_prob = ftract_prob[:-2][:, :-2]\n",
    "\n",
    "print(bundle_prob.shape)\n",
    "print(ftract_prob.shape)\n",
    "\n",
    "node_centers = load(op.join(path_to_data, f\"roi_centers-ftract-scale{scale}.pkl\"))[:82]\n",
    "\n",
    "scale_to_nroi = {1:\"33\", 2:\"60\", 3:\"125\"}\n",
    "\n",
    "labels = np.genfromtxt(op.join(path_to_data, f\"brain_labels.csv\"), dtype=str)\n",
    "\n",
    "print(f\"There are {len(labels)} nodes in the graph\")\n",
    "all_types = [\"lh\", \"rh\", \"lhsc\", \"rhsc\"]\n",
    "types_rename = [\"Left\", \"Right\", \"Left-sub\", \"Right-sub\"]\n",
    "type2num = {t:i for i, t in enumerate(all_types)}\n",
    "\n",
    "node_type = [type2num[lab.split(\"-\")[0]] for lab in labels]\n",
    "\n",
    "k_threshold = 1\n",
    "for k_threshold in np.arange(0, 1, 0.1):\n",
    "    # k_threshold = 0\n",
    "\n",
    "    k_matrix = (2 * bundle_prob * ftract_prob)/(ftract_prob + ftract_prob.T)\n",
    "\n",
    "    k_matrix = np.nan_to_num(k_matrix)\n",
    "\n",
    "    zorder=1\n",
    "    ls = \"-o\"\n",
    "    if k_threshold > 0:\n",
    "        zorder=0\n",
    "        ls = \"-\"\n",
    "        k_matrix = (k_matrix >= k_threshold).astype(int)\n",
    "\n",
    "    k_matrix -= np.diag(np.diag(k_matrix))\n",
    "\n",
    "    ## UNCOMMENT BELOW FOR UNDIRECTED\n",
    "#     k_matrix = (bundle_prob.copy() > k_threshold).astype(int)\n",
    "\n",
    "#     _, S, _ = dgsp.sorted_SVD(dgsp.modularity_matrix(k_matrix))\n",
    "#     plt.plot(S[:10], \"-o\", label=f\"t={k_threshold:1.2f}\")\n",
    "\n",
    "# k_matrix = (bundle_prob.copy() > 0.8).astype(int)\n",
    "\n",
    "## UNCOMMENT BELOW FOR SINGULAR VALUES SPECTRUM\n",
    "# _, S, _ = dgsp.sorted_SVD(dgsp.modularity_matrix(k_matrix))\n",
    "# plt.plot(S[:10], \"-o\", label=f\"Selected\", color=\"k\", lw=2, zorder=2)\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_atlas = datasets.fetch_atlas_schaefer_2018(n_rois=1000, yeo_networks=7)\n",
    "\n",
    "atlas_file = sch_atlas.maps\n",
    "atlas_img = nib.load(atlas_file)\n",
    "atlas_data = atlas_img.get_fdata().astype(int)\n",
    "\n",
    "path_to_ftract_atlas = op.join(path_to_data, f\"roi_atlas-ftract-scale1-GM.nii.gz\")\n",
    "laus_img = nib.load(path_to_ftract_atlas)\n",
    "\n",
    "laus_in_sch = image.resample_to_img(laus_img, atlas_img, interpolation=\"nearest\")\n",
    "laus_data = laus_in_sch.get_fdata().astype(int)\n",
    "\n",
    "all_networks = np.unique([lab.split(\"_\")[2] for lab in sch_atlas.labels.astype(str)])\n",
    "\n",
    "all_nodal_net = np.zeros((len(all_networks), len(k_matrix)))\n",
    "for net_id, selected_net in enumerate(all_networks):\n",
    "        is_dmn = [selected_net in lab for lab in sch_atlas.labels.astype(str)]\n",
    "        dmn_ids = np.where(is_dmn)[0]\n",
    "        dmn_data = np.isin(atlas_data, dmn_ids+1).astype(int)\n",
    "        all_nodal_net[net_id] = np.array([np.mean(dmn_data[laus_data == i]) for i in range(1, laus_data.max() + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dgsp)\n",
    "import seaborn as sns\n",
    "\n",
    "graph = k_matrix.copy()\n",
    "\n",
    "posx = 0\n",
    "posy = 1\n",
    "posz = 2\n",
    "edge_alpha = 0.4\n",
    "write_letter = True\n",
    "vmax = 0.6\n",
    "annot = True\n",
    "\n",
    "graph_pos = {i: (x, y) for i, (x, y) in enumerate(zip(node_centers[:, posx], node_centers[:, posy]))}\n",
    "\n",
    "U, S, Vh = dgsp.sorted_SVD(dgsp.modularity_matrix(graph))\n",
    "V = Vh.T\n",
    "\n",
    "n_nodes = len(S)\n",
    "\n",
    "vec_id = 0\n",
    "\n",
    "n_vec_max = 2\n",
    "n_kmeans = 12\n",
    "\n",
    "C_mat_out, c_pinv_out, C_mat_in, c_pinv_in, bimod_idx = dgsp.get_c_pinv(graph, n_vec_max, n_kmeans, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 4\n",
    "\n",
    "all_rec_from = np.zeros((n_trials, all_nodal_net.shape[0], all_nodal_net.shape[1]))\n",
    "all_rec_to = np.zeros_like(all_rec_from)\n",
    "all_rses = np.zeros((n_trials, len(all_networks)))\n",
    "all_rses_to = np.zeros((n_trials, len(all_networks)))\n",
    "corr_mat = np.zeros((n_trials+1, len(all_networks), len(all_networks)))\n",
    "corr_mat_to = np.zeros((n_trials+1, len(all_networks), len(all_networks)))\n",
    "\n",
    "# for i in range(n_trials):\n",
    "#     coefs_in = c_pinv_in @ x_hat_source\n",
    "#     x_hat_source = C_mat_out @ coefs_in\n",
    "\n",
    "#     all_rec[i] = x_hat_source\n",
    "#     all_corr[i] = pearsonr(x_hat_source, xt)[0]\n",
    "\n",
    "for net_i, selected_net in enumerate(all_nodal_net):\n",
    "    xt = selected_net\n",
    "\n",
    "    for j, net in enumerate(all_nodal_net):\n",
    "        corr_mat[0, net_i, j] = pearsonr(net, selected_net)[0]\n",
    "        corr_mat_to[0, net_i, j] = corr_mat[0, net_i, j]\n",
    "\n",
    "    last_rec = xt.copy()\n",
    "    last_rec_to = xt.copy()\n",
    "    for i in range(n_trials):\n",
    "        coefs_in = c_pinv_in @ last_rec\n",
    "        coefs_out = c_pinv_out @ last_rec_to\n",
    "        all_rec_from[i, net_i] = C_mat_out @ coefs_in\n",
    "        all_rec_to[i, net_i] = C_mat_in @ coefs_out\n",
    "\n",
    "        last_rec = all_rec_from[i, net_i]\n",
    "        last_rec_to = all_rec_from[i, net_i]\n",
    "\n",
    "        all_rses[i, net_i] = np.linalg.norm(all_rec_from[i, net_i] - xt)/np.linalg.norm(xt)\n",
    "        all_rses_to[i, net_i] = np.linalg.norm(all_rec_to[i, net_i] - xt)/np.linalg.norm(xt)\n",
    "\n",
    "        for j, net in enumerate(all_nodal_net):\n",
    "            corr_mat[i+1, net_i, j] = pearsonr(net, all_rec_from[i, net_i])[0]\n",
    "            corr_mat_to[i+1, j, net_i] = pearsonr(net, all_rec_to[i, net_i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, all_axes = plt.subplots(nrows=2, ncols=len(corr_mat), figsize=(len(corr_mat)*5, 10), gridspec_kw={\"wspace\": 0.2})\n",
    "\n",
    "thresh = 0.3\n",
    "\n",
    "manual_sort = [0, 1, 4, 2, 3, 5, 6]\n",
    "\n",
    "for i, corr in enumerate(corr_mat):\n",
    "    # sns.heatmap(corr, ax=axes[i], annot=True, cmap=\"turbo\", vmin=-0.5, vmax=0.5)\n",
    "\n",
    "    for axes, mat in zip(all_axes, [corr, corr_mat_to[i]]):\n",
    "        axes[i] = sns.heatmap(mat[manual_sort][:, manual_sort], cmap=\"turbo\", ax=axes[i], square=True, cbar=False,\n",
    "                            vmin=-0.5, vmax=0.5, linewidths=1, linecolor=\"k\")#, cbar_kws={\"shrink\": 0.8, \"pad\": 0.01})\n",
    "        axes[i].set_xticklabels([lab for lab in all_networks[manual_sort]], fontsize=8, rotation=45)\n",
    "        axes[i].set_yticklabels([lab for lab in all_networks[manual_sort]], fontsize=8, rotation=45)\n",
    "\n",
    "\n",
    "        for r, row in enumerate(mat[manual_sort][:, manual_sort]):\n",
    "            for j, val in enumerate(row):\n",
    "                if np.abs(val) >= thresh:\n",
    "                    axes[i].text(j+0.5, r+0.5, f\"{val:1.2f}\", ha=\"center\", va=\"center\", fontsize=12, color=\"w\")#, weight=\"semibold\")\n",
    "\n",
    "    all_axes[0, i].set_title(f\"Step {i}\", fontsize=18)\n",
    "    all_axes[0, i].set_xlabel(\"Network Signal\", fontsize=14)\n",
    "    all_axes[1, i].set_xlabel(\"Reconstructed Target\", fontsize=14)\n",
    "\n",
    "all_axes[0, 0].set_ylabel(\"Reconstructed Sender\", fontsize=14)\n",
    "all_axes[1, 0].set_ylabel(\"Network Signal\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual fMRI data\n",
    "\n",
    "@Deb: I put this data on the server so that you can access it easily (in the same format at `miplab-nas2/Data3/Alex/HCP-Graph/Laus2008_smth6_lp0.15`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_all_fmri = \"/Users/acionca/data/HCP-MIP/Laus2008_smth6_lp0.15\"\n",
    "# sub-100307_task-rest_dir-LR_timeseries.csv\n",
    "# sub-100307_task-motor_dir-LR_timeseries.csv\n",
    "\n",
    "sub = 100307\n",
    "task = \"motor\"\n",
    "# task = \"emotion\"\n",
    "# task = \"gambling\"\n",
    "# task = \"language\"\n",
    "fname = f\"sub-{sub}_task-{task}_dir-LR_timeseries.csv\"\n",
    "\n",
    "path_to_fmri = op.join(path_to_all_fmri, fname)\n",
    "nodal_fmri = np.genfromtxt(path_to_fmri, delimiter=\",\")\n",
    "\n",
    "print(nodal_fmri.shape)\n",
    "ntimepoints = len(nodal_fmri)\n",
    "\n",
    "maxval = np.max(np.abs(nodal_fmri))*0.7\n",
    "\n",
    "path_to_paradygm = op.join(path_to_all_fmri, fname.replace(\"timeseries\", \"regressor\"))\n",
    "paradygm = np.genfromtxt(path_to_paradygm, delimiter=\",\").astype(int)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "axes.imshow(nodal_fmri.T, aspect=\"auto\", cmap=\"turbo\", vmin=-maxval, vmax=maxval, interpolation=\"none\")\n",
    "\n",
    "# for para_val in np.unique(paradygm):\n",
    "maxval = paradygm.max()\n",
    "\n",
    "para_colors = [plt.get_cmap(\"Set1\")(i) for i in range(maxval)]\n",
    "para_cmap = LinearSegmentedColormap.from_list(\"\", [\"silver\"] + para_colors,)\n",
    "\n",
    "axes.scatter(np.arange(len(paradygm)), [-1]*len(paradygm), s=20, marker=\"s\",\n",
    "             c=paradygm, cmap=para_cmap)\n",
    "\n",
    "axes.set_ylabel(\"Node ID\", fontsize=16)\n",
    "axes.set_xlabel(\"Time\", fontsize=16)\n",
    "axes.tick_params(labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh = dgsp.sorted_SVD(dgsp.modularity_matrix(graph))\n",
    "\n",
    "plt.plot(S[:10], \"-o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dgsp)\n",
    "\n",
    "n_vec_max = 6\n",
    "n_kmeans = 4\n",
    "\n",
    "n_vec_max = 4\n",
    "n_kmeans = None\n",
    "n_kmeans = 45\n",
    "\n",
    "# n_vec_max = 4\n",
    "# n_kmeans = 4\n",
    "\n",
    "\n",
    "C_mat_out, c_pinv_out, C_mat_in, c_pinv_in, bimod_idx, edge_clusters, edge_clusters_mat = dgsp.get_c_pinv(graph, n_vec_max=n_vec_max, n_kmeans=n_kmeans, max_k=70,\n",
    "                                                                                                          normalize=False, verbose=True, return_clusters=True)\n",
    "\n",
    "all_mses = np.zeros((2, ntimepoints-2))\n",
    "all_corrs = np.zeros((2, ntimepoints-2))\n",
    "\n",
    "all_coefs = np.zeros((2, ntimepoints, n_kmeans))\n",
    "all_recon = np.zeros((2, ntimepoints-2, n_nodes))\n",
    "\n",
    "all_prop = np.zeros((2, n_kmeans, ntimepoints, n_nodes))\n",
    "\n",
    "for t, xt in enumerate(nodal_fmri):\n",
    "    all_coefs[0, t] = c_pinv_out @ xt\n",
    "    all_coefs[1, t] = c_pinv_in @ xt\n",
    "\n",
    "    if t > 0:\n",
    "        for k in range(n_kmeans):\n",
    "            k_indicator = (np.arange(n_kmeans) == k).astype(int)\n",
    "            all_prop[0, k, t] = C_mat_in @ (k_indicator*(c_pinv_in @ nodal_fmri[t]))\n",
    "            all_prop[1, k, t] = C_mat_out @ (k_indicator*(c_pinv_in @ nodal_fmri[t-1]))\n",
    "        \n",
    "        if t < ntimepoints - 1:\n",
    "            all_recon[0, t-1] = C_mat_out @ (c_pinv_in @ nodal_fmri[t+1])\n",
    "            all_recon[1, t-1] = C_mat_in @ (c_pinv_out @ nodal_fmri[t-1])\n",
    "\n",
    "\n",
    "            all_corrs[0, t-1] = pearsonr(all_recon[0, t-1], xt)[0]\n",
    "            all_corrs[1, t-1] = pearsonr(all_recon[1, t-1], xt)[0]\n",
    "\n",
    "            all_mses[0, t-1] = np.linalg.norm(all_recon[0, t-1] - xt)/np.linalg.norm(xt)\n",
    "            all_mses[1, t-1] = np.linalg.norm(all_recon[1, t-1] - xt)/np.linalg.norm(xt)\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8), gridspec_kw={\"wspace\":0, \"width_ratios\": [6, 1]}, sharey=\"row\")\n",
    "\n",
    "# axes[0, 0].set_ylabel(\"Correlation\", fontsize=16)\n",
    "# axes[1, 0].set_ylabel(\"RSE\", fontsize=16)\n",
    "\n",
    "# for ax in axes[:, 1]:\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# for i, data in enumerate([all_corrs, all_mses]):\n",
    "#     maxval = np.abs(data).max()\n",
    "#     for j, d in enumerate(data):\n",
    "#         axes[i, 0].plot(d, lw=2, alpha=0.8, label=[\"Send\", \"Receive\"][j])\n",
    "#         kdeplot(y=d, ax=axes[i, 1], alpha=0.5, linewidth=2, bw_adjust=0.5, fill=True)\n",
    "\n",
    "# axes[0, 0].set_ylim(-0.74, 0.74)\n",
    "# for ax in axes[:, 0]:\n",
    "#     ax.tick_params(labelsize=14)\n",
    "#     ax.legend(fontsize=14)\n",
    "\n",
    "plt.imshow(edge_clusters_mat, cmap=\"turbo\", interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the actual cell where things are happening !\n",
    "\n",
    "Currently, it's the previous approach where I try to estimate the \"switching table\" through the pseudoinverse of some weird matrix...\n",
    "\n",
    "@Deb: I added the updated approach below so that you can play around !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of SVD components to consider (look at the spectrum of singular values)\n",
    "n_vec_max = 4\n",
    "# Define the number of clusters/communities extracted through k-means\n",
    "# (you can set this to None with `verbose=True` in `dgsp.get_c_pinv` to see the best number of clusters)\n",
    "n_kmeans = 45\n",
    "\n",
    "C_mat_out, c_pinv_out, C_mat_in, c_pinv_in, bimod_idx = dgsp.get_c_pinv(graph, n_vec_max, n_kmeans, normalize=False, verbose=False)\n",
    "\n",
    "## Updated approach\n",
    "C_mat = np.concatenate([C_mat_out, C_mat_in])\n",
    "\n",
    "C_pinv = np.linalg.pinv(C_mat)\n",
    "print(C_pinv.shape)\n",
    "\n",
    "# Concatenating x_{t} and x_{t} for each timepoint\n",
    "x_concat = np.concatenate([nodal_fmri.T, nodal_fmri.T]).T\n",
    "\n",
    "# Concatenating x_{t} and x_{t} for each timepoint with x_{t} and x_{t+1} in between\n",
    "# x_concat = np.zeros((2*ntimepoints-1, 2*len(graph)))\n",
    "# x_concat[::2] = np.concatenate([nodal_fmri.T, nodal_fmri.T]).T\n",
    "# x_concat[1::2] = np.concatenate([nodal_fmri[:-1].T, nodal_fmri[ 1:].T]).T\n",
    "print(x_concat.shape)\n",
    "proj_signals = np.array([C_pinv @ x_t for x_t in x_concat])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(25, 12), gridspec_kw={\"hspace\":0.3, \"height_ratios\":[1, 2]})\n",
    "\n",
    "axes[0].set_title(\"Graph Signal\", fontsize=16)\n",
    "maxval = np.abs(x_concat).max()\n",
    "axes[0].imshow(x_concat.T, aspect=\"auto\", cmap=\"coolwarm\", interpolation=\"none\", vmin=-maxval, vmax=maxval)\n",
    "\n",
    "axes[0].set_xticks([])\n",
    "axes[0].tick_params(labelsize=14)\n",
    "plot.add_cbar(fig, axes[0])\n",
    "\n",
    "maxval = np.log(proj_signals.max())\n",
    "minval = -maxval\n",
    "\n",
    "axes[1].set_title(\"$\\mathbf{W}$ matrix\", fontsize=16)\n",
    "ax = axes[1]\n",
    "ax.imshow(proj_signals.T, cmap=\"coolwarm\", vmin=minval, vmax=maxval, aspect=\"auto\", interpolation=\"none\")\n",
    "\n",
    "ax.scatter(np.arange(len(paradygm)-1), [-2]*(len(paradygm)-1), s=20, marker=\"s\",\n",
    "            c=paradygm[:-1], cmap=para_cmap)\n",
    "\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.set_xlabel(\"Time\", fontsize=16)\n",
    "# ax.set_xlim(-0.9, n_timepoints-1.1)\n",
    "ax.set_ylabel(\"Bicommunity\", fontsize=16)\n",
    "_ = plot.add_cbar(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the **old** approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vec_max = 4\n",
    "n_kmeans = 45\n",
    "\n",
    "C_mat_out, c_pinv_out, C_mat_in, c_pinv_in, bimod_idx = dgsp.get_c_pinv(graph, n_vec_max, n_kmeans, normalize=False, verbose=False)\n",
    "\n",
    "W_out = (c_pinv_out @ nodal_fmri.T)\n",
    "\n",
    "b_vectors = np.zeros((n_kmeans, ntimepoints - 1))\n",
    "for i, w_out in enumerate(W_out.T[:-1]):\n",
    "    D_mat = C_mat_in @ np.diag(w_out)\n",
    "    D_pinv = np.linalg.pinv(D_mat, rcond=1e-10)\n",
    "\n",
    "    b_vectors[:, i] = D_pinv @ nodal_fmri[i+1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 4))\n",
    "\n",
    "maxval = np.log(b_vectors.max())\n",
    "minval = -maxval\n",
    "        \n",
    "ax.imshow(b_vectors, cmap=\"turbo\", vmin=minval, vmax=maxval, aspect=\"auto\", interpolation=\"none\")\n",
    "\n",
    "ax.scatter(np.arange(len(paradygm)-1), [-1]*(len(paradygm)-1), s=10, marker=\"s\",\n",
    "            c=paradygm[:-1], cmap=para_cmap)\n",
    "\n",
    "if n_kmeans == 12:\n",
    "    ax.plot([-0.5, ntimepoints-1.5], [n_kmeans//3-0.5, n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "    ax.plot([-0.5, ntimepoints-1.5], [2*n_kmeans//3-0.5, 2*n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "\n",
    "ax.tick_params(labelsize=14)\n",
    "ax.set_xlabel(\"Time\", fontsize=16)\n",
    "plot.add_cbar(fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(16, 4))\n",
    "\n",
    "D_mat = C_mat_in @ np.diag(c_pinv_out @ nodal_fmri[0])\n",
    "D_pinv = np.linalg.pinv(D_mat)\n",
    "axes[0].imshow(D_mat.T, aspect=\"auto\", cmap=\"turbo\", interpolation=\"none\")\n",
    "plot.add_cbar(fig, axes[0])\n",
    "\n",
    "axes[1].imshow(D_pinv, aspect=\"auto\", cmap=\"turbo\", interpolation=\"none\")\n",
    "plot.add_cbar(fig, axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_residuals = np.zeros((2, n_kmeans, ntimepoints, n_nodes))\n",
    "\n",
    "for k in range(n_kmeans):\n",
    "    for t in range(ntimepoints):\n",
    "        k_residuals[0, k, t] = nodal_fmri[t] - all_prop[0, k, t]\n",
    "        k_residuals[1, k, t] = nodal_fmri[t] - all_prop[1, k, t]\n",
    "\n",
    "all_residuals = np.zeros((2, ntimepoints, n_nodes))\n",
    "\n",
    "all_residuals[0] = [nodal_fmri[t] - all_prop[0, :, t].sum(axis=0) for t in range(ntimepoints)]\n",
    "all_residuals[1] = [nodal_fmri[t] - all_prop[1, :, t].sum(axis=0) for t in range(ntimepoints)]\n",
    "\n",
    "all_rse = (np.linalg.norm(all_residuals, axis=-1)/np.linalg.norm(nodal_fmri, axis=-1))\n",
    "print(all_rse.shape)\n",
    "\n",
    "all_corrs = np.array([pearsonr(all_residuals[0, t], all_residuals[1, t])[0] for t in range(ntimepoints)])\n",
    "# all_corrs = np.array([pearsonr(res1, res2)[0] for res1, res2 in zip(all_residuals[0], all_residuals[1])])\n",
    "print(all_corrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 8), gridspec_kw={\"wspace\":0, \"width_ratios\": [6, 1]}, sharey=\"row\")\n",
    "\n",
    "axes[1, 0].set_ylabel(\"Correlation\", fontsize=16)\n",
    "axes[0, 0].set_ylabel(\"Residual RSE\", fontsize=16)\n",
    "\n",
    "for ax in axes[:, 1]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "all_data = [all_rse, [all_corrs, all_corrs]]\n",
    "labels = [\"$C^{{in}}C^{{in\\dagger}}\\mathbf{{x}}_{{t+1}}$\",\n",
    "          \"$C^{{in}}C^{{out\\dagger}}\\mathbf{{x}}_{{t}}$\"]\n",
    "\n",
    "for i, data in enumerate(all_data):\n",
    "    maxval = np.abs(data).max()\n",
    "    for j, d in enumerate(data):\n",
    "        axes[i, 0].plot(d, lw=2, alpha=0.8, label=labels[j])\n",
    "        kdeplot(y=d, ax=axes[i, 1], alpha=0.5, linewidth=2, bw_adjust=0.5, fill=True)\n",
    "\n",
    "    axes[i, 0].scatter(np.arange(len(paradygm)), [0]*len(paradygm), s=20, marker=\"s\",\n",
    "                       c=paradygm, cmap=para_cmap)\n",
    "\n",
    "for ax in axes[:, 0]:\n",
    "    ax.tick_params(labelsize=14)\n",
    "\n",
    "axes[0, 0].legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_rse = (np.linalg.norm(k_residuals, axis=-1)/np.linalg.norm(nodal_fmri, axis=-1))\n",
    "print(k_rse.shape)\n",
    "\n",
    "k_corrs = np.zeros((n_kmeans, ntimepoints))\n",
    "for k in range(n_kmeans):\n",
    "    for t in range(ntimepoints):\n",
    "        k_corrs[k, t] = pearsonr(k_residuals[0, k, t], k_residuals[1, k, t])[0]\n",
    "# all_corrs = np.array([pearsonr(res1, res2)[0] for res1, res2 in zip(all_residuals[0], all_residuals[1])])\n",
    "print(k_corrs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k_rse.shape)\n",
    "print(k_corrs.shape)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, figsize=(18, 6), sharex=True, gridspec_kw={\"hspace\": 0, \"height_ratios\": [0.2, 1, 1]})\n",
    "\n",
    "axes[0].plot(all_corrs, color=\"k\", lw=2)\n",
    "axes[0].set_yticks([])\n",
    "\n",
    "axes[0].hlines(0.8, -0.5, ntimepoints-1.5, color=\"r\", lw=1, ls=\"--\")\n",
    "\n",
    "for i, (ax, val) in enumerate(zip(axes[1:], [k_rse, k_corrs])):\n",
    "    if i == 0:\n",
    "        val = val[0] - val[1]\n",
    "        maxval = val.max()\n",
    "        minval = -maxval\n",
    "    else:\n",
    "        maxval = 1\n",
    "        minval = 0\n",
    "        \n",
    "    ax.imshow(val, cmap=\"turbo\", vmin=minval, vmax=maxval, aspect=\"auto\", interpolation=\"none\")\n",
    "\n",
    "    ax.scatter(np.arange(len(paradygm)-1), [-0.75]*(len(paradygm)-1), s=10, marker=\"s\",\n",
    "               c=paradygm[:-1], cmap=para_cmap)\n",
    "\n",
    "    ax.plot([-0.5, ntimepoints-1.5], [n_kmeans//3-0.5, n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "    ax.plot([-0.5, ntimepoints-1.5], [2*n_kmeans//3-0.5, 2*n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "\n",
    "    title = [\"Residual RSE\", \"Correlation\"][i]\n",
    "    ax.set_ylabel(f\"{title}\", fontsize=16)\n",
    "    ax.tick_params(labelsize=14)\n",
    "\n",
    "axes[1].set_xlabel(\"Time\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, figsize=(18, 6), sharex=True, gridspec_kw={\"hspace\": 0.1})\n",
    "\n",
    "maxval = np.abs(all_coefs).max()*0.5\n",
    "\n",
    "for i, (ax, coefs) in enumerate(zip(axes, all_coefs)):\n",
    "    ax.imshow(coefs.T, cmap=\"turbo\", vmin=-maxval, vmax=maxval, aspect=\"auto\", interpolation=\"none\")\n",
    "\n",
    "    ax.plot([-0.5, ntimepoints-0.5], [n_kmeans//3-0.5, n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "    ax.plot([-0.5, ntimepoints-0.5], [2*n_kmeans//3-0.5, 2*n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "\n",
    "    title = [\"Sending\", \"Receiving\"][i]\n",
    "    ax.set_ylabel(f\"{title}\\nCoefficients\", fontsize=16)\n",
    "    ax.tick_params(labelsize=14)\n",
    "\n",
    "axes[1].set_xlabel(\"Time\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 5))\n",
    "\n",
    "# w^{diff}_{t} = w^{out}_{t} - w^{in}_{t-1}\n",
    "coefs_diff = all_coefs[0, :-1] - all_coefs[1, 1:]\n",
    "coefs_diff = coefs_diff/coefs_diff.max(axis=0)\n",
    "# (w^{out}_{t} + w^{in}_{t-1})/2\n",
    "coefs_avg = (np.abs(all_coefs[0, :-1]) + np.abs(all_coefs[1, 1:]))/2\n",
    "coefs_avg = coefs_avg/coefs_avg.max(axis=0)\n",
    "\n",
    "# (1 - w^{diff}_{t}) * w^{avg}_{t}\n",
    "# 1 if w^{diff}_{t} = 0 and w^{avg}_{t} = 1\n",
    "# The bigger the difference the smaller the value and the smaller the average the smaller the value\n",
    "# coefs_cons = (np.abs(coefs_diff).max() - coefs_diff)*coefs_avg\n",
    "coefs_cons = (1 - coefs_diff)*coefs_avg\n",
    "\n",
    "maxval = np.abs(coefs_cons).max()\n",
    "maxval = 1\n",
    "\n",
    "ntm = ax.imshow(coefs_cons.T, cmap=\"turbo\", vmin=-maxval, vmax=maxval, aspect=\"auto\", interpolation=\"none\")\n",
    "plt.colorbar(ntm)\n",
    "\n",
    "ax.plot([-0.5, ntimepoints-1.5], [n_kmeans//3-0.5, n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "ax.plot([-0.5, ntimepoints-1.5], [2*n_kmeans//3-0.5, 2*n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"--\")\n",
    "\n",
    "ax.set_xlabel(\"Time\", fontsize=16)\n",
    "ax.set_ylabel(f\"Bicommunity \\\"Usage\\\"\", fontsize=16)\n",
    "ax.tick_params(labelsize=14)\n",
    "\n",
    "for y_para in np.linspace(-1, -0.5, 4):\n",
    "    ax.scatter(np.arange(len(paradygm)-1), [y_para]*(len(paradygm)-1), s=10, marker=\"s\",\n",
    "            c=paradygm[:-1], cmap=para_cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(figsize=(18, 4), ncols=2, gridspec_kw={\"wspace\": 0.05, \"width_ratios\": [4, 1]})\n",
    "fig, allaxes = plt.subplots(figsize=(18, 10), nrows=2, ncols=2, gridspec_kw={\"wspace\": 0.05, \"hspace\":0.3, \"width_ratios\": [4, 1]})\n",
    "\n",
    "com_coher = all_coefs[0][:-1] * all_coefs[1][1:]\n",
    "diff_coher = all_coefs[1][1:] - all_coefs[0][:-1]\n",
    "\n",
    "coher_titles = [f\"Coherency $(\\mathbf{{w}}^\\\\text{{out}}_{{t}}[k]\\cdot\\mathbf{{w}}^\\\\text{{in}}_{{t+1}}[k])$\",\n",
    "                f\"Coherency $(\\mathbf{{w}}^\\\\text{{in}}_{{t+1}}[k] - \\mathbf{{w}}^\\\\text{{out}}_{{t}}[k])$\"]\n",
    "for ax_i, (axes, coher) in enumerate(zip(allaxes, [com_coher, diff_coher])):\n",
    "\n",
    "    maxval = np.abs(com_coher).max()*0.9\n",
    "    maxval = 8\n",
    "    if ax_i == 0:\n",
    "        maxval = 10\n",
    "\n",
    "    axes[0].imshow(coher.T, cmap=\"turbo\", vmin=-maxval, vmax=maxval, aspect=\"auto\", interpolation=\"none\")\n",
    "\n",
    "    axes[0].plot([-0.5, ntimepoints-1.5], [n_kmeans//3-0.5, n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"-\")\n",
    "    axes[0].plot([-0.5, ntimepoints-1.5], [2*n_kmeans//3-0.5, 2*n_kmeans//3-0.5], color=\"k\", lw=2, ls=\"-\")\n",
    "\n",
    "    axes[0].set_title(coher_titles[ax_i], fontsize=16)\n",
    "    axes[0].set_ylabel(f\"Bicommunity $(k)$\", fontsize=16)\n",
    "    axes[0].tick_params(labelsize=14)\n",
    "    axes[0].set_xlabel(\"Time\", fontsize=16)\n",
    "\n",
    "    coef_thresh = 0.75\n",
    "    groups = [\"Self\", \"Within\", \"Between\"]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "    axes[1].set_title(f\"Top {100*(1-coef_thresh):2.1f}%\", fontsize=16)\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    gs = GridSpecFromSubplotSpec(3, 1, subplot_spec=axes[1], hspace=0)\n",
    "    axes_kde = [fig.add_subplot(gs[i]) for i in range(3)]\n",
    "    y_upper = 0\n",
    "\n",
    "    if ax_i == 0:\n",
    "        denom = 3\n",
    "        max_x = 40\n",
    "    else:\n",
    "        denom = 1\n",
    "        coef_thresh = 1 - coef_thresh\n",
    "        max_x = 5\n",
    "\n",
    "    for i in range(3):\n",
    "        kde_sig = coher[:, 4*i:4*(i+1)].flatten()\n",
    "        perc_thresh = np.percentile(np.abs(kde_sig), 100*coef_thresh)\n",
    "\n",
    "        fltr = np.abs(kde_sig) > perc_thresh\n",
    "        if ax_i > 0:\n",
    "            fltr = np.abs(kde_sig) < perc_thresh\n",
    "\n",
    "        whatev = kdeplot(x=kde_sig[fltr], ax=axes_kde[i], alpha=0.4, linewidth=2, bw_adjust=0.5, fill=True, label=groups[i], color=colors[i], clip=(-max_x, max_x))\n",
    "\n",
    "        ymax = whatev.get_position().bounds[1]\n",
    "        y_upper = max([ymax, y_upper])\n",
    "\n",
    "        axes_kde[i].set_yticks([])\n",
    "        axes_kde[i].set_ylabel(\"\")\n",
    "        axes_kde[i].set_xlim(-max_x, max_x)\n",
    "        if i < 2:\n",
    "            axes_kde[i].set_xticks([])\n",
    "\n",
    "        axes_kde[i].text(x=0.05, y=0.9, s=groups[i], ha=\"left\", va=\"top\", fontsize=14, transform=axes_kde[i].transAxes)\n",
    "    axes_kde[-1].tick_params(labelsize=14)\n",
    "\n",
    "    # for ax in axes_kde:\n",
    "    #     ax.set_ylim(0, y_upper/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=12, figsize=(30, 8), gridspec_kw={\"wspace\":0, \"hspace\":0}, sharex=\"row\", sharey=True)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Diff. Coherency\", fontsize=14)\n",
    "axes[1, 0].set_ylabel(\"Diff. Coherency\", fontsize=14)\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\", ntimepoints)\n",
    "for k in range(12):\n",
    "\n",
    "    axes[0, k].set_title(f\"\\nBicommunity {k+1}\", fontsize=16)\n",
    "    axes[1, k].set_xlabel(f\"Coefficients\", fontsize=14)\n",
    "\n",
    "    all_data = np.vstack([all_coefs[0][:-1][:, k], diff_coher[:, k]]).T\n",
    "    for t, (start, finish) in enumerate(zip(all_data[:-1], all_data[1:])):\n",
    "        x, y = zip(start, finish)\n",
    "        axes[0, k].plot(x, y, lw=2, alpha=1, color=cmap(t))\n",
    "        x = all_coefs[1][:-1][t:t+2, k]\n",
    "        y = diff_coher[t:t+2, k]\n",
    "        axes[1, k].plot(x, y, lw=2, alpha=1, color=cmap(t))\n",
    "        \n",
    "    # axes[0, k].plot(all_coefs[0][:-1][:, k], diff_coher[:, k], alpha=0.3)\n",
    "    # axes[1, k].plot(all_coefs[1][1:][:, k], diff_coher[:, k], alpha=0.3)\n",
    "    # axes[0, k].scatter(all_coefs[0][:-1][:, k], diff_coher[:, k], alpha=0.3, s=20, edgecolor=\"none\", c=np.arange(len(diff_coher[:, k])), cmap=\"turbo\")\n",
    "    # axes[1, k].scatter(all_coefs[1][1:][:, k], diff_coher[:, k], alpha=0.3, s=20, edgecolor=\"none\", c=np.arange(len(diff_coher[:, k])), cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=12, figsize=(30, 8), gridspec_kw={\"wspace\":0, \"hspace\":0}, sharex=\"row\", sharey=True)\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Prod. Coherency\", fontsize=14)\n",
    "axes[1, 0].set_ylabel(\"Prod. Coherency\", fontsize=14)\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\", ntimepoints)\n",
    "for k in range(12):\n",
    "\n",
    "    axes[0, k].set_title(f\"\\nBicommunity {k+1}\", fontsize=16)\n",
    "    axes[1, k].set_xlabel(f\"Coefficients\", fontsize=14)\n",
    "\n",
    "    all_data = np.vstack([all_coefs[0][:-1][:, k], com_coher[:, k]]).T\n",
    "    for t, (start, finish) in enumerate(zip(all_data[:-1], all_data[1:])):\n",
    "        x, y = zip(start, finish)\n",
    "        axes[0, k].plot(x, y, lw=2, alpha=1, color=cmap(t))\n",
    "        x = all_coefs[1][:-1][t:t+2, k]\n",
    "        y = com_coher[t:t+2, k]\n",
    "        axes[1, k].plot(x, y, lw=2, alpha=1, color=cmap(t))\n",
    "        \n",
    "    # axes[0, k].plot(all_coefs[0][:-1][:, k], diff_coher[:, k], alpha=0.3)\n",
    "    # axes[1, k].plot(all_coefs[1][1:][:, k], diff_coher[:, k], alpha=0.3)\n",
    "    # axes[0, k].scatter(all_coefs[0][:-1][:, k], diff_coher[:, k], alpha=0.3, s=20, edgecolor=\"none\", c=np.arange(len(diff_coher[:, k])), cmap=\"turbo\")\n",
    "    # axes[1, k].scatter(all_coefs[1][1:][:, k], diff_coher[:, k], alpha=0.3, s=20, edgecolor=\"none\", c=np.arange(len(diff_coher[:, k])), cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dgsp)\n",
    "\n",
    "all_nvecs = [2, 3, 4, 5, 6]\n",
    "all_kmeans = np.arange(4, 30, 2)\n",
    "\n",
    "all_mses = np.zeros((len(all_nvecs), len(all_kmeans), 2, ntimepoints-2))\n",
    "all_corrs = np.zeros((len(all_nvecs), len(all_kmeans), 2, ntimepoints-2))\n",
    "\n",
    "for n, n_vec_max in enumerate(all_nvecs):\n",
    "    for k, n_kmeans in enumerate(all_kmeans):\n",
    "        C_mat_out, c_pinv_out, C_mat_in, c_pinv_in, bimod_idx = dgsp.get_c_pinv(graph, n_vec_max, n_kmeans, normalize=False, verbose=False)\n",
    "\n",
    "        for t, xt in enumerate(nodal_fmri):\n",
    "            if (t > 0) and (t < ntimepoints - 1):\n",
    "                x_sender = C_mat_out @ (c_pinv_in @ nodal_fmri[t+1])\n",
    "                x_receive = C_mat_in @ (c_pinv_out @ nodal_fmri[t-1])\n",
    "\n",
    "                all_corrs[n, k, 0, t-1] = pearsonr(x_sender, xt)[0]\n",
    "                all_corrs[n, k, 1, t-1] = pearsonr(x_receive, xt)[0]\n",
    "\n",
    "                all_mses[n, k, 0, t-1] = np.linalg.norm(x_sender - xt)/np.linalg.norm(xt)\n",
    "                all_mses[n, k, 1, t-1] = np.linalg.norm(x_receive - xt)/np.linalg.norm(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 5))\n",
    "\n",
    "maxcor = 0.7\n",
    "maxerr = 5\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks(np.arange(len(all_kmeans)), labels=all_kmeans)\n",
    "    ax.set_yticks(np.arange(len(all_nvecs)), labels=all_nvecs)\n",
    "\n",
    "# axes[0, 0].imshow(all_corrs[:, :, 0].max(axis=-1), cmap=\"turbo\", vmin=-maxcor, vmax=maxcor)\n",
    "# axes[1, 0].imshow(all_corrs[:, :, 1].max(axis=-1), cmap=\"turbo\", vmin=-maxcor, vmax=maxcor)\n",
    "\n",
    "axes[0, 0].imshow(np.percentile(all_corrs[:, :, 0], 90, axis=-1), cmap=\"turbo\", vmin=-maxcor, vmax=maxcor)\n",
    "axes[1, 0].imshow(np.percentile(all_corrs[:, :, 1], 90, axis=-1), cmap=\"turbo\", vmin=-maxcor, vmax=maxcor)\n",
    "\n",
    "# axes[0, 1].imshow(all_mses[:, :, 0].mean(axis=-1), cmap=\"turbo\", vmin=0, vmax=3)\n",
    "# axes[1, 1].imshow(all_mses[:, :, 1].mean(axis=-1), cmap=\"turbo\", vmin=0, vmax=3)\n",
    "\n",
    "axes[0, 1].imshow(np.percentile(all_mses[:, :, 0], 90, axis=-1), cmap=\"turbo\", vmin=0, vmax=maxerr)\n",
    "axes[1, 1].imshow(np.percentile(all_mses[:, :, 1], 90, axis=-1), cmap=\"turbo\", vmin=0, vmax=maxerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_fmri = \"/Users/acionca/data/HCP-MIP/Laus2008_smth6_lp0.15\" # /sub-100307_task-rest_dir-LR_timeseries.csv\"\n",
    "\n",
    "all_fmris = [f for f in os.listdir(path_to_fmri) if \".csv\" in f]\n",
    "\n",
    "all_nodal_fmris = [np.genfromtxt(op.join(path_to_fmri, f), delimiter=\",\") for f in all_fmris]\n",
    "\n",
    "for nodal_fmri in all_nodal_fmris:\n",
    "    print(nodal_fmri.shape)\n",
    "\n",
    "n_vec_max = 2\n",
    "n_kmeans = 12\n",
    "\n",
    "C_mat_out, c_pinv_out, C_mat_in, c_pinv_in, bimod_idx = dgsp.get_c_pinv(graph, n_vec_max, n_kmeans, normalize=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logscale = False\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(all_nodal_fmris), figsize=(len(all_nodal_fmris)*5, 5),\n",
    "                         sharey=True, gridspec_kw={\"wspace\":0})\n",
    "\n",
    "for s_i, nodal_fmri in enumerate(all_nodal_fmris):\n",
    "    print(nodal_fmri.shape)\n",
    "\n",
    "    ntimepoints = len(nodal_fmri)\n",
    "\n",
    "    # Coefficients\n",
    "    all_coefs = np.zeros((2, ntimepoints, n_kmeans))\n",
    "    all_recon = np.zeros((2, ntimepoints-2, n_nodes))\n",
    "\n",
    "    for t, xt in enumerate(nodal_fmri):\n",
    "        all_coefs[0, t] = c_pinv_out @ xt\n",
    "        all_coefs[1, t] = c_pinv_in @ xt\n",
    "\n",
    "        if (t > 0) and (t < ntimepoints - 1):\n",
    "            all_recon[0, t-1] = C_mat_out @ (c_pinv_in @ nodal_fmri[t+1])\n",
    "            all_recon[1, t-1] = C_mat_in @ (c_pinv_out @ nodal_fmri[t-1])\n",
    "\n",
    "    # Coherency\n",
    "    com_coher = all_coefs[0][:-1] * all_coefs[1][1:]\n",
    "    \n",
    "    coef_thresh = 0.7\n",
    "    if logscale:\n",
    "        coef_thresh = 0\n",
    "    groups = [\"Self\", \"Within\", \"Between\"]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "    for i in range(3):\n",
    "        kde_sig = com_coher[:, 4*i:4*(i+1)].flatten()\n",
    "        perc_thresh = np.percentile(np.abs(kde_sig), 100*coef_thresh)\n",
    "        kdeplot(x=kde_sig[np.abs(kde_sig) > perc_thresh], ax=axes[s_i], alpha=0.4, linewidth=2,\n",
    "                bw_adjust=0.5, fill=True, label=groups[i], color=colors[i], clip=(-40, 40))\n",
    "\n",
    "    axes[s_i].set_title(\"HCP\" + all_fmris[s_i].split(\"_\")[0], fontsize=16)\n",
    "    axes[s_i].set_xlim(-25, 25)\n",
    "    axes[s_i].tick_params(labelsize=14)\n",
    "    axes[s_i].legend(fontsize=14, loc=\"upper left\")\n",
    "\n",
    "    if logscale:\n",
    "        axes[s_i].set_yscale(\"log\")\n",
    "        axes[s_i].set_ylim(1e-3, 1)\n",
    "\n",
    "        axes[s_i].hlines(1e-1, -25, 25, color=\"k\", lw=1, ls=\"--\")\n",
    "        axes[s_i].hlines(1e-2, -25, 25, color=\"k\", lw=1, ls=\"--\")\n",
    "    \n",
    "    axes[s_i].set_xlabel(\"Coherency\", fontsize=16)\n",
    "    \n",
    "axes[0].set_ylabel(\"Density\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
